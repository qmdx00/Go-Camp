### 问题一

> 总结限流，熔断，降级的常用方式，重试的注意事项，负载均衡的常用方式。

#### 隔离

##### 服务隔离

- 动静隔离：加速、缓存访问变换频率次数小的。比如CDN场景中间静态资源和动态API分离。
- 读写分离：主从，CQRS，Replicaset

##### 轻重隔离

- 核心隔离：业务按照Level进行资源池划分(L0/L1/L2)
    - 核心、非核心的故障域的差异隔离(机器资源、依赖资源)
    - 多级群，通过冗余资源来提升吞吐和容灾能力

##### 轻重隔离

- 快慢隔离: 把服务的吞吐想象成一个池，当突然的洪流进来时，池子需要一定时间排放完，这时候其它支流在池子里待的时间取决于前面的排放能力，耗时增加，会对小请求产生影响。
    - 按照各种纬度进行隔离：sink、部门、业务、logId、重要性(S/A/B/C)

- 热点隔离：热点即经常访问的数据，很多时候我们希望统计某个热点数据中访问频次最高的Top K数据，并对其访问进行缓存。
    - 小表广播：从remotecache 提升为 localcache，app定时更新，甚至可以让运营平台支持广播刷新localcache。atomic.Value
    - 主动预热：比如直播房间页高在线情况下bypass监控主动防御。

##### 物理隔离

- 进程隔离：容器化(Dcoker)，容器编排引擎(k8s)。

- 集群隔离：一个应用，物理上部署多套，通过cluster区分。

#### 超时控制

超时控制，我们的组件能够快速失效(fail fast),因为服务是相互调用的，所以在延迟堆叠前，腰特别注意超时的操作。

- 网络传递具有不确定性
- 客户端和服务端不一致的超时策略导致资源浪费
- 默认值策略
- 高延迟服务导致client浪费资源等待，使用超时传递：进程间传递+跨进程传递。 实际业务开发中，我们依赖的微服务的超时策略并不清楚，随着业务迭代耗时发生了变化，意外的导致一来这出现了超时

服务提供者定义好Latency SLO，更新到gRPC Proto 定义中，服务后续迭代，都应该保证SLO

- kit 基础库兜底默认超时，比如100ms，进行配置防御保护，避免出现类似60s之类的超大超时策略
- 配置中心公共模板，对于未配置的服务使用公共配置。

超时传递，当上游服务已经超时返回 504，但下游服务仍然在执行，会导致浪费资源做无用功。超时传递指的是把当前服务的剩余 Quota 传递到下游服务中，继承超时策略，控制请求级别的全局超时控制

- 进程内超时控制：一个请求在每个阶段(网络请求)开始前，就要检查是否还有足够的剩余来处理请求，以及继承他的超时策略，使用 Go 标准库的 context.WithTimeout。

#### 过载保护

计算系统临近过载时的峰值吞吐作为限流的阈值来进行流量控制，达到系统保护。

- 服务器临近过载时，主动抛弃一定量的负载，目标是自保。
- 在系统稳定的前提下，保持系统的吞吐量。 常见做法：利特尔法则
- CPU、内存作为信号量进行节流。
- 队列管理: 队列长度、LIFO。
- 可控延迟算法: CoDel。

#### 限流

限流是指在一段时间内，定义某个客户或应用可以接收或处理多少个请求的技术。例如，通过限流，你可以过滤掉产生流量峰值的客户和微服务，或者可以确保你的应用程序在自动扩展（Auto Scaling）失效前都不会出现过载的情况。

- 令牌桶、漏桶 针对单个节点，无法分布式限流。
- QPS 限流
    - 不同的请求可能需要数量迥异的资源来处理。
    - 某种静态 QPS 限流不是特别准。
- 给每个用户设置限制
    - 全局过载发生时候，针对某些“异常”进行控制。
    - 一定程度的“超卖”配额。
- 按照优先级丢弃。
- 拒绝请求也需要成本。

##### 令牌桶算法

一个存放固定容量令牌的桶，按照固定速率往桶里面添加令牌，描述如下：

- 假设限制2r/s，则按照500ms的固定速率往桶里面添加令牌
- 桶中最多存放b个令牌，当桶满时，添加新的令牌会被丢弃或拒绝。
- 当一个n个字节大小的数据包到达，将从桶中删除n个令牌，接着数据包被发送到网络上。
- 如果桶中的令牌不足n个，则不会删除令牌，且该数据包将被限流，要么丢弃要么缓冲区等待。

##### 漏桶算法

作为计量工具时，可以用于流量整形和流量控制，漏桶算法描述如下：

- 一个固定容量的漏桶，按照常亮固定速率流出水滴。
- 如果桶是空的，则不需流出水滴。
- 可以以任意速率流入水滴到漏桶。
- 如果流入水滴超出了桶的容量，则流入的水滴溢出了被丢弃，而漏桶容量是不变的。

漏斗桶/令牌桶确实能够保护系统不被拖垮, 但不管漏斗桶还是令牌桶, 其防护思路都是设定一个指标,
当超过该指标后就阻止或减少流量的继续进入，当系统负载降低到某一水平后则恢复流量的进入。但其通常都是被动的，其实际效果取决于限流阈值设置是否合理，但往往设置合理不是一件容易的事情。

- 集群增加机器或者减少机器限流阈值是否要重新设置?
- 设置限流阈值的依据是什么?
- 人力运维成本是否过高?
- 当调用方反馈429时, 这个时候重新设置限流, 其实流量高峰已经过了重新评估限流是否有意义?

这些其实都是采用漏斗桶/令牌桶的缺点, 总体来说就是太被动, 不能快速适应流量变化。 因此我们需要一种自适应的限流算法，即:
过载保护，根据系统当前的负载自动丢弃流量。

#### 熔断

断路器（Circuit Breakers）:
为了限制操作的持续时间，我们可以使用超时，超时可以防止挂起操作并保证系统可以响应。因为我们处于高度动态的环境中，几乎不可能确定在每种情况下都能正常工作的准确的时间限制。断路器以现实世界的电子元件命名，因为它们的行为是都是相同的。断路器在分布式系统中非常有用，因为重复的故障可能会导致雪球效应，并使整个系统崩溃。

#### 降级

通过降级回复来减少工作量，或者丢弃不重要的请求。而且需要了解哪些流量可以降级，并且有能力区分不同的请求。我们通常提供降低回复的质量来答复减少所需的计算量或者时间。我们自动降级通常需要考虑几个点：

- 确定具体采用哪个指标作为流量评估和优雅降级的决定性指标（如，CPU、延迟、队列长度、线程数量、错误等）。
- 当服务进入降级模式时，需要执行什么动作？
- 流量抛弃或者优雅降级应该在服务的哪一层实现？是否需要在整个服务的每一层都实现，还是可以选择某个高层面的关键节点来实现？

同时我们要考虑一下几点：

- 优雅降级不应该被经常触发 - 通常触发条件现实了容量规划的失误，或者是意外的负载。
- 演练，代码平时不会触发和使用，需要定期针对一小部分的流量进行演练，保证模式的正常。
- 应该足够简单。

降级本质为: 提供有损服务。

- UI 模块化，非核心模块降级。
    - BFF 层聚合 API，模块降级。
- 页面上一次缓存副本。
- 默认值、热门推荐等。
- 流量拦截 + 定期数据缓存(过期副本策略)。

处理策略

- 页面降级、延迟服务、写/读降级、缓存降级
- 抛异常、返回约定协议、Mock 数据、Fallback 处理

#### 重试

当请求返回错误（例: 配额不足、超时、内部错误等），对于 backend 部分节点过载的情况下，倾向于立刻重试，但是需要留意重试带来的流量放大:

- 限制重试次数和基于重试分布的策略（重试比率: 10%）。
- 随机化、指数型递增的重试周期: exponential ackoff + jitter。
- client 测记录重试次数直方图，传递到 server，进行分布判定，交由 server 判定拒绝。
- 只应该在失败的这层进行重试，当重试仍然失败，全局约定错误码“过载，无须重试”，避免级联重试。

重试问题

- Nginx upstream retry 过大，导致服务雪崩。
- 业务不幂等，导致的重试，数据重复。
    - 全局唯一 ID: 根据业务生成一个全局唯一 ID，在调用接口时会传入该 ID，接口提供方会从相应的存储系统比如 redis 中去检索这个全局 ID
      是否存在，如果存在则说明该操作已经执行过了，将拒绝本次服务请求；否则将相应该服务请求并将全局 ID 存入存储系统中,之后包含相同业务 ID 参数的请求将被拒绝。
    - 去重表: 这种方法适用于在业务中有唯一标识的插入场景。比如在支付场景中，一个订单只会支付一次，可以建立一张去重表,将订单 ID
      作为唯一索引。把支付并且写入支付单据到去重表放入一个事务中了，这样当出现重复支付时，数据库就会抛出唯一约束异常,操作就会回滚。这样保证了订单只会被支付一次。
    - 多版本并发控制: 适合对更新请求作幂等性控制,比如要更新商品的名字，这是就可以在更新的接口中增加一个版本号来做幂等性控制。
- 多层级重试传递，放大流量引起雪崩。

#### 负载均衡

数据中心内部的负载均衡 在理想情况下，某个服务的负载会完全均匀地分发给所有的后端任务。在任何时刻，最忙和最不忙的节点永远消耗同样数量的CPU。

目标：

- 均衡的流量分发。
- 可靠的识别异常节点。
- scale-out，增加同质节点扩容。
- 减少错误，提高可用性。
